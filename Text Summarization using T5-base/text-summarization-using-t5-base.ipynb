{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":2734496,"datasetId":1654566,"databundleVersionId":2779611,"isSourceIdPinned":false}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" \n# Using the CNN/DailyMail News Dataset\n\n# In this notebook, we fine-tune the [T5-base](https://huggingface.co/t5-base) model for abstractive text summarization.  \n# We use the CNN/DailyMail dataset, which contains news articles paired with human-written highlights.  \n# The goal is to train a model that can generate concise and accurate summaries of long documents.  \n","metadata":{}},{"cell_type":"markdown","source":"## Setup and Dataset Download\n\n###  In this step, we install the required libraries, import dependencies,  \n###  and download the CNN/DailyMail dataset from Kaggle.\n","metadata":{}},{"cell_type":"code","source":"!pip install rouge_score\n!pip install evaluate\nimport numpy as np \nimport pandas as pd\nimport kagglehub\nimport os\nimport kagglehub\nimport re\nfrom datasets import Dataset\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport evaluate\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\n\npath = kagglehub.dataset_download(\"gowrishankarp/newspaper-text-summarization-cnn-dailymail\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:32:28.042072Z","iopub.execute_input":"2025-08-25T00:32:28.043179Z","iopub.status.idle":"2025-08-25T00:32:34.742859Z","shell.execute_reply.started":"2025-08-25T00:32:28.043144Z","shell.execute_reply":"2025-08-25T00:32:34.741969Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\nPath to dataset files: /kaggle/input/newspaper-text-summarization-cnn-dailymail\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Reading the data","metadata":{}},{"cell_type":"markdown","source":"## Load Dataset\n\n###  Load the training, validation, and test splits into pandas DataFrames","metadata":{}},{"cell_type":"code","source":"training_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\ntest_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\nvalidation_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\ntraining_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:32:42.750091Z","iopub.execute_input":"2025-08-25T00:32:42.750933Z","iopub.status.idle":"2025-08-25T00:33:12.769833Z","shell.execute_reply.started":"2025-08-25T00:32:42.750899Z","shell.execute_reply":"2025-08-25T00:33:12.769153Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         id  \\\n0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n2  00027e965c8264c35cc1bc55556db388da82b07f   \n3  0002c17436637c4fe1837c935c04de47adb18e9a   \n4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n\n                                             article  \\\n0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n1  (CNN) -- Ralph Mata was an internal affairs li...   \n2  A drunk driver who killed a young woman in a h...   \n3  (CNN) -- With a breezy sweep of his pen Presid...   \n4  Fleetwood are the only team still to have a 10...   \n\n                                          highlights  \n0  Bishop John Folda, of North Dakota, is taking ...  \n1  Criminal complaint: Cop used his role to help ...  \n2  Craig Eccleston-Todd, 27, had drunk at least t...  \n3  Nina dos Santos says Europe must be ready to a...  \n4  Fleetwood top of League One after 2-0 win at S...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n      <td>Criminal complaint: Cop used his role to help ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n      <td>A drunk driver who killed a young woman in a h...</td>\n      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n      <td>Nina dos Santos says Europe must be ready to a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n      <td>Fleetwood are the only team still to have a 10...</td>\n      <td>Fleetwood top of League One after 2-0 win at S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"###  Droped Unused Column","metadata":{}},{"cell_type":"code","source":"training_set.drop(columns = ['id'],inplace = True)\ntest_set.drop(columns = ['id'],inplace = True)\nvalidation_set.drop(columns = ['id'],inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:35:11.155305Z","iopub.execute_input":"2025-08-25T00:35:11.155575Z","iopub.status.idle":"2025-08-25T00:35:11.190611Z","shell.execute_reply.started":"2025-08-25T00:35:11.155556Z","shell.execute_reply":"2025-08-25T00:35:11.190041Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## checking for nulls","metadata":{}},{"cell_type":"code","source":"print(training_set.isnull().sum())\nprint(training_set.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:35:35.250129Z","iopub.execute_input":"2025-08-25T00:35:35.250751Z","iopub.status.idle":"2025-08-25T00:35:35.337972Z","shell.execute_reply.started":"2025-08-25T00:35:35.250723Z","shell.execute_reply":"2025-08-25T00:35:35.337253Z"}},"outputs":[{"name":"stdout","text":"article       0\nhighlights    0\ndtype: int64\n(287113, 2)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"###  droped the duplicates","metadata":{}},{"cell_type":"code","source":"training_set.drop_duplicates(inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:37:00.901081Z","iopub.execute_input":"2025-08-25T00:37:00.901361Z","iopub.status.idle":"2025-08-25T00:37:03.612622Z","shell.execute_reply.started":"2025-08-25T00:37:00.901340Z","shell.execute_reply":"2025-08-25T00:37:03.612018Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## checking the data size","metadata":{}},{"cell_type":"code","source":"print(training_set.shape)\nprint(validation_set.shape)\nprint(test_set.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:37:06.892080Z","iopub.execute_input":"2025-08-25T00:37:06.892374Z","iopub.status.idle":"2025-08-25T00:37:06.897438Z","shell.execute_reply.started":"2025-08-25T00:37:06.892354Z","shell.execute_reply":"2025-08-25T00:37:06.896449Z"}},"outputs":[{"name":"stdout","text":"(284015, 2)\n(13368, 2)\n(11490, 2)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Sampling the Dataset\n\n###  Since the CNN/DailyMail dataset is large,  \n###  we take smaller random samples for training","metadata":{}},{"cell_type":"code","source":"training_set = training_set.sample(n=40_000, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:38:30.653688Z","iopub.execute_input":"2025-08-25T00:38:30.654365Z","iopub.status.idle":"2025-08-25T00:38:30.668495Z","shell.execute_reply.started":"2025-08-25T00:38:30.654340Z","shell.execute_reply":"2025-08-25T00:38:30.667755Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"training_set.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:38:35.368685Z","iopub.execute_input":"2025-08-25T00:38:35.369312Z","iopub.status.idle":"2025-08-25T00:38:35.374298Z","shell.execute_reply.started":"2025-08-25T00:38:35.369289Z","shell.execute_reply":"2025-08-25T00:38:35.373614Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(40000, 2)"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Text Cleaning\n\n###  For summarization, we apply minimal cleaning:  \n###  - Remove extra spaces and line breaks.  \n###  - Keep punctuation, casing, and sentence structure intact (important for meaning).  \n\n###  This ensures the text remains close to the original while removing noise.\n","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:41:22.874292Z","iopub.execute_input":"2025-08-25T00:41:22.875075Z","iopub.status.idle":"2025-08-25T00:41:22.878602Z","shell.execute_reply.started":"2025-08-25T00:41:22.875047Z","shell.execute_reply":"2025-08-25T00:41:22.877874Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"training_set['article'] = training_set['article'].apply(clean_text)\ntraining_set['highlights'] = training_set['highlights'].apply(clean_text)\n\nvalidation_set['article'] = validation_set['article'].apply(clean_text)\nvalidation_set['highlights'] = validation_set['highlights'].apply(clean_text)\n\ntest_set['article'] = test_set['article'].apply(clean_text)\ntest_set['highlights'] = test_set['highlights'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:41:32.632966Z","iopub.execute_input":"2025-08-25T00:41:32.633704Z","iopub.status.idle":"2025-08-25T00:41:47.612597Z","shell.execute_reply.started":"2025-08-25T00:41:32.633674Z","shell.execute_reply":"2025-08-25T00:41:47.611767Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Convert DataFrames to Hugging Face Datasets\n\n###   Convert the pandas DataFrames for training, validation, and testing  \n###   into the `datasets.Dataset` format, which is required for use with the Hugging Face Trainer API.\n","metadata":{}},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(training_set)\ntest_dataset = Dataset.from_pandas(test_set)\nvalidation_dataset = Dataset.from_pandas(validation_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:42:38.572158Z","iopub.execute_input":"2025-08-25T00:42:38.572537Z","iopub.status.idle":"2025-08-25T00:42:41.084911Z","shell.execute_reply.started":"2025-08-25T00:42:38.572510Z","shell.execute_reply":"2025-08-25T00:42:41.084309Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"###   Load the pretrained **T5-base tokenizer** from Hugging Face.  \n###   The tokenizer converts raw text into token IDs that the model can understand,  \n###   and will also handle decoding model outputs back into text.","metadata":{}},{"cell_type":"code","source":"model_name = 't5-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name,use_fast = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:44:31.971672Z","iopub.execute_input":"2025-08-25T00:44:31.972001Z","iopub.status.idle":"2025-08-25T00:44:33.770376Z","shell.execute_reply.started":"2025-08-25T00:44:31.971978Z","shell.execute_reply":"2025-08-25T00:44:33.769791Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c3976a12494a90ae228f59139d8849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9790095634e44cfd9726281b5c5f0c35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c619677f674c7c91f1d97d10e8621c"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Preprocessing Function\n\n###   Define a preprocessing function to tokenize the dataset:  \n###   - **Articles** are truncated/padded to a maximum length of 512 tokens.  \n###   - **Summaries (highlights)** are truncated/padded to a maximum length of 128 tokens.  \n###   - The tokenized summaries are stored as labels for training.","metadata":{}},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 128\n\ndef preprocess_data(data):\n    model_inputs = tokenizer(\n        data[\"article\"],\n        max_length=max_input_length,\n        truncation=True,\n        padding=\"max_length\"  \n    )\n\n    labels = tokenizer(\n        data[\"highlights\"],\n        max_length=max_target_length,\n        truncation=True,\n        padding=\"max_length\" \n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:46:24.513871Z","iopub.execute_input":"2025-08-25T00:46:24.514204Z","iopub.status.idle":"2025-08-25T00:46:24.518946Z","shell.execute_reply.started":"2025-08-25T00:46:24.514181Z","shell.execute_reply":"2025-08-25T00:46:24.518234Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_data, batched=True)\nvalidation_dataset   = validation_dataset.map(preprocess_data, batched=True)\ntest_dataset  = test_dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:46:32.949248Z","iopub.execute_input":"2025-08-25T00:46:32.950039Z","iopub.status.idle":"2025-08-25T00:48:15.649823Z","shell.execute_reply.started":"2025-08-25T00:46:32.950010Z","shell.execute_reply":"2025-08-25T00:48:15.649133Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7888649cbea8477696db0613cc6ba9f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1ef5b34b9a472c86b272fb2baeaa72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e675c2595674eac9db4e7b12c77f563"}},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Load Pretrained Model and Data Collator\n\n### - Load the pretrained **T5-base** model for sequence-to-sequence learning.  \n###   - Use a `DataCollatorForSeq2Seq` to handle dynamic padding and batching during training.  \n###   - Suppress unnecessary log messages for cleaner output.\n","metadata":{}},{"cell_type":"code","source":"transformers.logging.set_verbosity_error()\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:49:19.526005Z","iopub.execute_input":"2025-08-25T00:49:19.526307Z","iopub.status.idle":"2025-08-25T00:49:23.953941Z","shell.execute_reply.started":"2025-08-25T00:49:19.526285Z","shell.execute_reply":"2025-08-25T00:49:23.953108Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed0cb78a56e43c19dca732c48b84516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7133f688f6da42f79b2d6ff094cf92f8"}},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Evaluation Metric (ROUGE)\n\n###  Define the evaluation function using **ROUGE scores**, which are standard for text summarization:  \n###  - Decode model predictions and labels back into text.  \n###  - Replace `-100` values in labels (ignored tokens) with the padding token ID.  \n###  - Compute ROUGE metrics (ROUGE-1, ROUGE-2, ROUGE-L) with stemming enabled.  \n###  - Return the F-measure for each metric.\n","metadata":{}},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    \n    result = {k: v.mid.fmeasure if hasattr(v, \"mid\") else v for k, v in result.items()}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T00:50:50.739377Z","iopub.execute_input":"2025-08-25T00:50:50.739731Z","iopub.status.idle":"2025-08-25T00:50:51.816074Z","shell.execute_reply.started":"2025-08-25T00:50:50.739708Z","shell.execute_reply":"2025-08-25T00:50:51.815447Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986c97d4e7514fcc92ecd788e940cd82"}},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## Training the Model\n\n###  Set up the `Seq2SeqTrainer` with the model, datasets, tokenizer, and data collator.  \n###  - Evaluate and save checkpoints every 500 steps.  \n###  - Use gradient accumulation, mixed precision (FP16), and gradient checkpointing for efficiency.  \n###  - Track ROUGE scores and load the best model at the end.  \n###  - Save the trained model and tokenizer for later use.\n","metadata":{}},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"steps\",\n    eval_steps=500,     \n    save_strategy=\"steps\",\n    save_steps=500,            \n    learning_rate=2e-5,               \n    per_device_train_batch_size=8,    \n    per_device_eval_batch_size=8,     \n    gradient_accumulation_steps=4,    \n    num_train_epochs=3,              \n    weight_decay=0.01,                \n    save_total_limit=3,               \n    predict_with_generate=True,       \n    fp16=True,                        \n    logging_dir=\"./logs\",\n    logging_steps=50,                \n    warmup_ratio=0.1,                 \n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rougeL\",\n    greater_is_better=True,\n    disable_tqdm=False\n)\n\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"/kaggle/working/model\")\ntokenizer.save_pretrained(\"/kaggle/working/model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T01:01:35.584189Z","iopub.execute_input":"2025-08-25T01:01:35.584539Z","iopub.status.idle":"2025-08-25T07:44:20.392921Z","shell.execute_reply.started":"2025-08-25T01:01:35.584517Z","shell.execute_reply":"2025-08-25T07:44:20.391996Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/681577659.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 6:42:37, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.963800</td>\n      <td>1.011992</td>\n      <td>0.253002</td>\n      <td>0.120670</td>\n      <td>0.206532</td>\n      <td>0.206520</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.967300</td>\n      <td>0.995584</td>\n      <td>0.254662</td>\n      <td>0.122702</td>\n      <td>0.208850</td>\n      <td>0.208863</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.976900</td>\n      <td>1.006711</td>\n      <td>0.252555</td>\n      <td>0.118501</td>\n      <td>0.205762</td>\n      <td>0.205767</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.999400</td>\n      <td>1.010226</td>\n      <td>0.252192</td>\n      <td>0.118189</td>\n      <td>0.205508</td>\n      <td>0.205491</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.977600</td>\n      <td>1.010280</td>\n      <td>0.252185</td>\n      <td>0.118183</td>\n      <td>0.205484</td>\n      <td>0.205472</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.974700</td>\n      <td>1.010252</td>\n      <td>0.252199</td>\n      <td>0.118189</td>\n      <td>0.205509</td>\n      <td>0.205494</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.935000</td>\n      <td>1.010200</td>\n      <td>0.252239</td>\n      <td>0.118251</td>\n      <td>0.205533</td>\n      <td>0.205521</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/my_model/tokenizer_config.json',\n '/kaggle/working/my_model/special_tokens_map.json',\n '/kaggle/working/my_model/spiece.model',\n '/kaggle/working/my_model/added_tokens.json',\n '/kaggle/working/my_model/tokenizer.json')"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Continue Training for Metric Improvement\n\nContinuing training for 1 additional epoch to boost ROUGE metrics, using:\n- Lower learning rate (1e-5) for stable updates\n- Larger effective batch size (gradient accumulation = 8)\n- Resume from last checkpoint\n\nThis enhances performance without restarting from scratch.\n","metadata":{}},{"cell_type":"code","source":"training_args.num_train_epochs += 1             \ntraining_args.learning_rate = 1e-5            \ntraining_args.gradient_accumulation_steps = 8\ntraining_args.eval_steps = 625\ntraining_args.save_steps = 625\n\n\ntrainer.train(resume_from_checkpoint=True)\n\nmodel.save_pretrained(\"/kaggle/working/model_epoch4\")\ntokenizer.save_pretrained(\"/kaggle/working/model_epoch4\")\n","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating the model","metadata":{}},{"cell_type":"markdown","source":"#### epoch 3","metadata":{}},{"cell_type":"code","source":"print(\"Evaluation started...\")\nmetrics = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Evaluation finished.\")\nprint(f\"Test Metrics = {metrics}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:18:45.132937Z","iopub.execute_input":"2025-08-25T10:18:45.133197Z","iopub.status.idle":"2025-08-25T10:38:46.418966Z","shell.execute_reply.started":"2025-08-25T10:18:45.133177Z","shell.execute_reply":"2025-08-25T10:38:46.418307Z"}},"outputs":[{"name":"stdout","text":"Evaluation started...\nEvaluation finished.\nTest Metrics = {'eval_loss': 0.9585846066474915, 'eval_rouge1': 0.25719530653966755, 'eval_rouge2': 0.12255452754943658, 'eval_rougeL': 0.21060603655786417, 'eval_rougeLsum': 0.21065662546819633, 'eval_runtime': 1201.2774, 'eval_samples_per_second': 9.565, 'eval_steps_per_second': 1.196, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"#### epoch 4   ","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/working/model_epoch4\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/model_epoch4\")\n\nmodel.to(device)\n\ntrainer.model = model\n\nprint(\"Evaluation started...\")\nmetrics = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Evaluation finished.\")\nprint(f\"Test Metrics = {metrics}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:46:48.302736Z","iopub.execute_input":"2025-08-25T10:46:48.303021Z","iopub.status.idle":"2025-08-25T11:06:01.512241Z","shell.execute_reply.started":"2025-08-25T10:46:48.303000Z","shell.execute_reply":"2025-08-25T11:06:01.511567Z"}},"outputs":[{"name":"stdout","text":"Evaluation started...\nEvaluation finished.\nTest Metrics = {'eval_loss': 0.9585416913032532, 'eval_rouge1': 0.25714058396703954, 'eval_rouge2': 0.12249156911185319, 'eval_rougeL': 0.21057529343683054, 'eval_rougeLsum': 0.21062441406766758, 'eval_runtime': 1152.5395, 'eval_samples_per_second': 9.969, 'eval_steps_per_second': 1.247, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}